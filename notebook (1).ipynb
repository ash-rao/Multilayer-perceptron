{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data = pd.read_csv('../input/train.csv')\ntest_data= pd.read_csv('../input/test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1b396fc5-c81e-4be9-b6a7-0608b7cb7eac",
        "collapsed": true,
        "_uuid": "701b202ed145df665299de1a9a9872211a3d4a8d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#convert categorical values into numeric \ncleanup = { 'Sex': {'male':1, 'female':0}, 'Embarked':{'S':0, 'C':1, 'Q':2}}\ntrain_data.replace(cleanup, inplace= True)\ntest_data.replace(cleanup, inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "38b33816-243c-42e5-bffb-25ef510d5545",
        "collapsed": true,
        "_uuid": "c4f8025ccd3510d63e2d7d7a5ed01b22453e8b25",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Keep only relevant features (name and passenger ID are not relevant)\ntrain_data= train_data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Embarked']]\ntest_data= test_data[[ 'Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Embarked']]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "eebb26b0-6758-4b02-b445-b2768cd667f3",
        "collapsed": true,
        "_uuid": "376bf712b38aa312bf5fdaba1352f7c9325a10ff",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Drop null and missing values\ntrain_data = train_data.dropna()\ntest_data = test_data.dropna()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a7e13762-4a22-4df8-9f85-4075fc5875c3",
        "_uuid": "e31a1ac36086cbfb036f354e53cf02ccbd355f13",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Scale all attribute values to between 0 and 1\nmin_max=MinMaxScaler()\nTrain_data_scaled =min_max.fit_transform(train_data[['Survived','Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Embarked']])\nTest_data_scaled =min_max.fit_transform(test_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Embarked']])\nprint(Train_data_scaled.shape) #Number of rows in training set\n\nprint(Test_data_scaled.shape) #number of rows in test set \n\nXtrain = []\nYtrain = []\nfor i in range(Train_data_scaled.shape[0]):\n    Ytrain.append(Train_data_scaled[i][0])\n    Xtrain.append(list(Train_data_scaled[i][1:]))\nXtrain = np.array(Xtrain)\nYtrain = np.array(Ytrain)\nTrain_data_Xtf = tf.convert_to_tensor(Xtrain, np.float32)\nTrain_data_Ytf = tf.convert_to_tensor(Ytrain, np.float32)\n\nTest_data_Xtf = tf.convert_to_tensor(Test_data_scaled, np.float32)\nTest_data_Xtf.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9658172d-c7d4-4601-a37b-a1f0bf99b32c",
        "collapsed": true,
        "_uuid": "781fefedac270db92736e78e821394ac2fcc5a3c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "learning_rate = 0.001\ntraining_epochs = 15 #Number of iterations\nbatch_size = 50 #50 samples per iteration\ndisplay_step =1\nhidden1 =16  #16 neurons in first hidden layer\nhidden2 = 16 \ninputlayer = 6 #6 inputs - Pclass, Sex, Age, sibsp, Fare, Embarked\noutputlayer = 1 #1 output - survived \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "db2d7127-4040-4b91-bf3c-34b5727ae469",
        "collapsed": true,
        "_uuid": "b88a849a9e3ac3e808521078198ee448be176d32",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Placeholders for X - input and Y - output\nX = tf.placeholder(\"float\", [None, inputlayer])\nY = tf.placeholder(\"float\", [None, outputlayer])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1a5ef6cb-42fc-4ca9-aa82-eb8c9f7375c0",
        "collapsed": true,
        "_uuid": "85da88c6a310a2afd91ded73f525fe3257b19cc8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Randomly initialized weights and biases\nweights = {\n    'h1': tf.Variable(tf.random_normal([inputlayer, hidden1])),\n    'h2': tf.Variable(tf.random_normal([hidden1, hidden2])),\n    'out': tf.Variable(tf.random_normal([hidden2, outputlayer]))\n}\nbiases = {\n    'b1': tf.Variable(tf.random_normal([hidden1])),\n    'b2': tf.Variable(tf.random_normal([hidden2])),\n    'out': tf.Variable(tf.random_normal([outputlayer]))\n}\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "96b1da39-d077-43a6-b82e-ce022ae85b54",
        "_uuid": "3c34eb6b4523efa7119164109d87a210cac10ae1",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def multilayer_perceptron(x):\n    # Hidden fully connected layer with 256 neurons\n    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n    # Hidden fully connected layer with 256 neurons\n    \n    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n    # Output fully connected layer with a neuron for each class\n    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n    return out_layer\nloss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n    logits=multilayer_perceptron(X), labels=Y))\n\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n# Initializing the variables\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost = 0.\n        total_batch = int(int(Train_data_Xtf.get_shape()[0])/batch_size)\n        # Loop over all batches\n        print(total_batch)\n        for i in range(total_batch):\n            batch_x = Train_data_Xtf[i*total_batch: total_batch+i*total_batch+1].eval()\n            batch_y = Train_data_Ytf[i*total_batch: total_batch+i*total_batch+1].eval()\n            batch_x=batch_x.reshape(-1,6)\n            batch_y=batch_y.reshape(-1,1)\n            \n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,\n                                                            Y: batch_y})\n            \n            # Compute average loss\n            avg_cost += c / total_batch\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n    print(\"Optimization Finished!\")\n\n    # Test model\n    pred = tf.nn.softmax(multilayer_perceptron(X))  # Apply softmax to logits\n    predicted_class = tf.greater(pred,0.5)\n    correct = tf.equal(predicted_class, tf.equal(Y,1.0))\n    accuracy = tf.reduce_mean( tf.cast(correct, 'float') )\n    test_acc = sess.run(accuracy, feed_dict={X: Test_data_Xtf.eval().reshape(-1,6), Y: Train_data_Ytf[:331].eval().reshape(-1,1)})\n    print (\"Test accuracy: %.3f\" % (test_acc))\n                        \n                                      \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "57c4daa8-0ec7-4be3-a607-7065012584c3",
        "collapsed": true,
        "_uuid": "496f1e8b69fb4428bb7cf8c0970312a4500bce22",
        "trusted": false
      },
      "cell_type": "code",
      "source": "Test_data_Xtf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ee26600a-3591-4510-bc5c-262df2652401",
        "collapsed": true,
        "_uuid": "bb5e753f7a8e026a1725ef00a65b1a5453f24bd6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}